{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "# os.chdir('/home/mbortkie/repos/crl_subgoal')\n",
    "import wandb\n",
    "\n",
    "from rb import TrajectoryUniformSamplingQueue, jit_wrap, segment_ids_per_row\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Tuple, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "import chex\n",
    "from flax import struct\n",
    "from absl import app, flags\n",
    "from ml_collections import config_flags\n",
    "from impls.agents import agents\n",
    "from impls.agents.crl import CRLAgent, get_config\n",
    "from config import ROOT_DIR\n",
    "from block_moving_env import *\n",
    "from main import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap environment\n",
    "NUM_ENVS = 1024\n",
    "MAX_REPLAY_SIZE = 10000\n",
    "BATCH_SIZE = 1024\n",
    "EPISODE_LENGTH = 100\n",
    "NUM_ACTIONS = 6\n",
    "GRID_SIZE = 10\n",
    "NUM_BOXES = 10\n",
    "SEED = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:30:03.084757: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3022] Can't reduce memory use below 8.61GiB (9243810148 bytes) by rematerialization; only reduced to 8.70GiB (9338880080 bytes), down from 8.70GiB (9338880080 bytes) originally\n"
     ]
    }
   ],
   "source": [
    "env = BoxPushingEnv(grid_size=GRID_SIZE, max_steps=EPISODE_LENGTH, number_of_boxes=NUM_BOXES)\n",
    "env = AutoResetWrapper(env)\n",
    "key = random.PRNGKey(SEED)\n",
    "env.step = jax.jit(jax.vmap(env.step))\n",
    "env.reset = jax.jit(jax.vmap(env.reset))\n",
    "jitted_flatten_batch = jax.jit(jax.vmap(flatten_batch, in_axes=(None, 0, 0)), static_argnums=(0,))\n",
    "\n",
    "# Replay buffer\n",
    "dummy_timestep = TimeStep(\n",
    "    key=key,\n",
    "    grid=jnp.zeros((GRID_SIZE, GRID_SIZE), dtype=jnp.int32),\n",
    "    target_cells=jnp.zeros((NUM_BOXES, 2), dtype=jnp.int32),\n",
    "    agent_pos=jnp.zeros((2,), dtype=jnp.int32),\n",
    "    agent_has_box=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    steps=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    action=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    goal=jnp.zeros((GRID_SIZE, GRID_SIZE), dtype=jnp.int32),\n",
    "    reward=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    done=jnp.zeros((1,), dtype=jnp.int32),\n",
    ")\n",
    "replay_buffer = jit_wrap(\n",
    "    TrajectoryUniformSamplingQueue(\n",
    "        max_replay_size=MAX_REPLAY_SIZE,\n",
    "        dummy_data_sample=dummy_timestep,\n",
    "        sample_batch_size=BATCH_SIZE,\n",
    "        num_envs=NUM_ENVS,\n",
    "        episode_length=EPISODE_LENGTH,\n",
    "    )\n",
    ")\n",
    "buffer_state = jax.jit(replay_buffer.init)(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent creation\n",
      "Agent created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Agent\n",
    "config = get_config()\n",
    "config['discrete'] = True\n",
    "agent_class = agents[config['agent_name']]\n",
    "example_batch = {\n",
    "    'observations':dummy_timestep.grid.reshape(1, -1),  # Add batch dimension \n",
    "    'actions': jnp.ones((1,), dtype=jnp.int32) * (NUM_ACTIONS-1), # TODO: make sure it should be the maximal value of action space  # Single action for batch size 1\n",
    "    'value_goals': dummy_timestep.grid.reshape(1, -1),\n",
    "    'actor_goals': dummy_timestep.grid.reshape(1, -1),\n",
    "}\n",
    "\n",
    "print(\"Testing agent creation\")\n",
    "agent = agent_class.create(\n",
    "    SEED,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'],\n",
    "    config,\n",
    "    example_batch['value_goals'],\n",
    ")\n",
    "print(\"Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_key = random.PRNGKey(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_step(carry, _):\n",
    "    buffer_state, agent, key = carry\n",
    "    key, batch_key, double_batch_key = jax.random.split(key, 3)\n",
    "    # Sample and process transitions\n",
    "    buffer_state, transitions = replay_buffer.sample(buffer_state)\n",
    "    batch_keys = jax.random.split(batch_key, transitions.grid.shape[0])\n",
    "    state, future_state, goal_index = jitted_flatten_batch(0.99, transitions, batch_keys)\n",
    "\n",
    "    state, actions, future_state, goal_index = apply_double_batch_trick(state, future_state, goal_index, double_batch_key)\n",
    "    # Create valid batch\n",
    "    valid_batch = {\n",
    "        'observations': state.grid.reshape(state.grid.shape[0], -1),\n",
    "        'actions': actions.squeeze(),\n",
    "        'value_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "        'actor_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "    }\n",
    "\n",
    "    # Update agent\n",
    "    agent, update_info = agent.update(valid_batch)\n",
    "    return (buffer_state, agent, key), update_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def train_epoch(carry, _):\n",
    "    buffer_state, agent, key = carry\n",
    "    key, data_key, up_key = jax.random.split(key, 3)\n",
    "    _, _, timesteps = collect_data(agent, data_key, env, NUM_ENVS, EPISODE_LENGTH)\n",
    "    buffer_state = replay_buffer.insert(buffer_state, timesteps)\n",
    "    (buffer_state, agent, _), _ = jax.lax.scan(update_step, (buffer_state, agent, up_key), None, length=1000)\n",
    "    return (buffer_state, agent, key), None\n",
    "\n",
    "@jax.jit\n",
    "def train_n_epochs(buffer_state, agent, key):\n",
    "    (buffer_state, agent, key), _ = jax.lax.scan(\n",
    "        train_epoch,\n",
    "        (buffer_state, agent, key),\n",
    "        None,\n",
    "        length=10,\n",
    "    )\n",
    "    return buffer_state, agent, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:30:25.649266: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3022] Can't reduce memory use below 337.76MiB (354166672 bytes) by rematerialization; only reduced to 8.81GiB (9460974608 bytes), down from 8.86GiB (9515837288 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "collect_data(agent, key, env, 1024, 100)\n",
    "update_step((buffer_state, agent, key), None)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect_data average time: 0.0254 ± 0.0011 seconds\n",
      "update_step average time: 0.0438 ± 0.1281 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Measure collect_data time over 10 executions\n",
    "collect_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    collect_data(agent, key, env, 1024, 100)\n",
    "    collect_time = time.time() - start_time\n",
    "    collect_times.append(collect_time)\n",
    "\n",
    "avg_collect_time = np.mean(collect_times)\n",
    "std_collect_time = np.std(collect_times)\n",
    "print(f\"collect_data average time: {avg_collect_time:.4f} ± {std_collect_time:.4f} seconds\")\n",
    "\n",
    "# Measure update_step time over 10 executions\n",
    "update_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    carry, _ = update_step((buffer_state, agent, key), None)\n",
    "    update_time = time.time() - start_time\n",
    "    (buffer_state, agent, key) = carry\n",
    "    update_times.append(update_time)\n",
    "\n",
    "avg_update_time = np.mean(update_times)\n",
    "std_update_time = np.std(update_times)\n",
    "print(f\"update_step average time: {avg_update_time:.4f} ± {std_update_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key splitting average time: 0.028839 ± 0.085857 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:30:39.253427: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3022] Can't reduce memory use below 270.04MiB (283154712 bytes) by rematerialization; only reduced to 8.78GiB (9432285316 bytes), down from 8.78GiB (9432289416 bytes) originally\n",
      "2025-07-01 22:30:49.666778: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.70GiB (rounded to 9338880000)requested by op \n",
      "2025-07-01 22:30:49.667153: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ***************************************************************************************************_\n",
      "E0701 22:30:49.667184 3198855 pjrt_stream_executor_client.cc:2917] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes. [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m     19\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     buffer_state, transitions = \u001b[43mreplay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     buffer_sample_time = time.time() - start_time\n\u001b[32m     22\u001b[39m     buffer_sample_times.append(buffer_sample_time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/crl_subgoal/src/rb.py:124\u001b[39m, in \u001b[36mTrajectoryUniformSamplingQueue.sample\u001b[39m\u001b[34m(self, buffer_state)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sample a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mself\u001b[39m.check_can_sample(buffer_state, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes."
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Measure key splitting time over 10 executions\n",
    "key_split_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    key, batch_key, double_batch_key = jax.random.split(key, 3)\n",
    "    key_split_time = time.time() - start_time\n",
    "    key_split_times.append(key_split_time)\n",
    "\n",
    "avg_key_split_time = np.mean(key_split_times)\n",
    "std_key_split_time = np.std(key_split_times)\n",
    "print(f\"key splitting average time: {avg_key_split_time:.6f} ± {std_key_split_time:.6f} seconds\")\n",
    "\n",
    "# Measure buffer sampling time over 10 executions\n",
    "buffer_sample_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    buffer_state, transitions = replay_buffer.sample(buffer_state)\n",
    "    buffer_sample_time = time.time() - start_time\n",
    "    buffer_sample_times.append(buffer_sample_time)\n",
    "\n",
    "avg_buffer_sample_time = np.mean(buffer_sample_times)\n",
    "std_buffer_sample_time = np.std(buffer_sample_times)\n",
    "print(f\"buffer sampling average time: {avg_buffer_sample_time:.6f} ± {std_buffer_sample_time:.6f} seconds\")\n",
    "\n",
    "# Measure batch key generation time over 10 executions\n",
    "batch_keys_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    batch_keys = jax.random.split(batch_key, transitions.grid.shape[0])\n",
    "    batch_keys_time = time.time() - start_time\n",
    "    batch_keys_times.append(batch_keys_time)\n",
    "\n",
    "avg_batch_keys_time = np.mean(batch_keys_times)\n",
    "std_batch_keys_time = np.std(batch_keys_times)\n",
    "print(f\"batch keys generation average time: {avg_batch_keys_time:.6f} ± {std_batch_keys_time:.6f} seconds\")\n",
    "\n",
    "# Measure flatten batch time over 10 executions\n",
    "flatten_batch_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    state, future_state, goal_index = jitted_flatten_batch(0.99, transitions, batch_keys)\n",
    "    flatten_batch_time = time.time() - start_time\n",
    "    flatten_batch_times.append(flatten_batch_time)\n",
    "\n",
    "avg_flatten_batch_time = np.mean(flatten_batch_times)\n",
    "std_flatten_batch_time = np.std(flatten_batch_times)\n",
    "print(f\"flatten batch average time: {avg_flatten_batch_time:.6f} ± {std_flatten_batch_time:.6f} seconds\")\n",
    "\n",
    "# Measure double batch trick time over 10 executions\n",
    "double_batch_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    apply_double_batch_trick(state, future_state, goal_index, double_batch_key)\n",
    "    double_batch_time = time.time() - start_time\n",
    "    double_batch_times.append(double_batch_time)\n",
    "\n",
    "avg_double_batch_time = np.mean(double_batch_times)\n",
    "std_double_batch_time = np.std(double_batch_times)\n",
    "print(f\"double batch trick average time: {avg_double_batch_time:.6f} ± {std_double_batch_time:.6f} seconds\")\n",
    "\n",
    "state, actions, future_state, goal_index = apply_double_batch_trick(state, future_state, goal_index, double_batch_key)\n",
    "\n",
    "\n",
    "# Measure batch creation time over 10 executions\n",
    "batch_creation_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    valid_batch = {\n",
    "        'observations': state.grid.reshape(state.grid.shape[0], -1),\n",
    "        'actions': actions.squeeze(),\n",
    "        'value_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "        'actor_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "    }\n",
    "    batch_creation_time = time.time() - start_time\n",
    "    batch_creation_times.append(batch_creation_time)\n",
    "\n",
    "avg_batch_creation_time = np.mean(batch_creation_times)\n",
    "std_batch_creation_time = np.std(batch_creation_times)\n",
    "print(f\"batch creation average time: {avg_batch_creation_time:.6f} ± {std_batch_creation_time:.6f} seconds\")\n",
    "\n",
    "# Measure agent update time over 10 executions\n",
    "agent_update_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    agent, update_info = agent.update(valid_batch)\n",
    "    agent_update_time = time.time() - start_time\n",
    "    agent_update_times.append(agent_update_time)\n",
    "\n",
    "avg_agent_update_time = np.mean(agent_update_times)\n",
    "std_agent_update_time = np.std(agent_update_times)\n",
    "print(f\"agent update average time: {avg_agent_update_time:.6f} ± {std_agent_update_time:.6f} seconds\")\n",
    "\n",
    "# Print total average time\n",
    "total_avg_time = avg_key_split_time + avg_buffer_sample_time + avg_batch_keys_time + avg_flatten_batch_time + avg_double_batch_time + avg_batch_creation_time + avg_agent_update_time\n",
    "total_std_time = np.sqrt(std_key_split_time**2 + std_buffer_sample_time**2 + std_batch_keys_time**2 + std_flatten_batch_time**2 + std_double_batch_time**2 + std_batch_creation_time**2 + std_agent_update_time**2)\n",
    "print(f\"total average time: {total_avg_time:.6f} ± {total_std_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 20:14:51.037675: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3022] Can't reduce memory use below 337.76MiB (354165852 bytes) by rematerialization; only reduced to 8.83GiB (9481893056 bytes), down from 8.86GiB (9515784168 bytes) originally\n",
      "2025-07-01 20:15:12.432393: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.70GiB (rounded to 9338880000)requested by op \n",
      "2025-07-01 20:15:12.432765: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ***************************************************************************************************_\n",
      "E0701 20:15:12.432839 3139955 pjrt_stream_executor_client.cc:2917] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes. [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXlaRuntimeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m      4\u001b[39m     start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     (buffer_state, agent, _), _ = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     scan_time = time.time() - start_time\n\u001b[32m      7\u001b[39m     scan_times.append(scan_time)\n",
      "    \u001b[31m[... skipping hidden 12 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/crl_subgoal/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1306\u001b[39m, in \u001b[36mExecuteReplicated.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1304\u001b[39m   \u001b[38;5;28mself\u001b[39m._handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m   results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxla_executable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dispatch.needs_check_special():\n\u001b[32m   1309\u001b[39m   out_arrays = results.disassemble_into_single_device_arrays()\n",
      "\u001b[31mXlaRuntimeError\u001b[39m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 9338880000 bytes."
     ]
    }
   ],
   "source": [
    "\n",
    "# Measure scan execution time over 10 executions\n",
    "scan_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    (buffer_state, agent, _), _ = jax.lax.scan(update_step, (buffer_state, agent, key), None, length=10)\n",
    "    scan_time = time.time() - start_time\n",
    "    scan_times.append(scan_time)\n",
    "\n",
    "avg_scan_time = np.mean(scan_times)\n",
    "std_scan_time = np.std(scan_times)\n",
    "print(f\"scan execution average time: {avg_scan_time:.6f} ± {std_scan_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "env = BoxPushingEnv(grid_size=GRID_SIZE, max_steps=EPISODE_LENGTH, number_of_boxes=NUM_BOXES)\n",
    "env = AutoResetWrapper(env)\n",
    "key = random.PRNGKey(SEED)\n",
    "# env.step = jax.jit(jax.vmap(env.step))\n",
    "# env.reset = jax.jit(jax.vmap(env.reset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 2, 2, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 2, 0, 3, 2],\n",
       "       [0, 0, 1, 0, 0, 2, 0, 0, 0, 2]], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 10, 10,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10, 10,  0, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10,  0,  3, 10],\n",
       "       [ 0,  0,  0,  0,  0, 10,  0,  0,  0, 10]], dtype=int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solved_state = env._env.create_solved_state(state)\n",
    "solved_state.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 2, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 2, 1, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 2, 2]], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_next, reward, done, info = env.step(solved_state, 2)\n",
    "state_next.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 True {'boxes_on_target': Array(10, dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._env._is_goal_reached(solved_state.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False | env._env._is_goal_reached(solved_state.grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
