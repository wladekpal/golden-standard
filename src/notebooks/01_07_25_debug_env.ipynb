{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "# os.chdir('/home/mbortkie/repos/crl_subgoal')\n",
    "import wandb\n",
    "\n",
    "from rb import TrajectoryUniformSamplingQueue, jit_wrap, segment_ids_per_row\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Tuple, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "import chex\n",
    "from flax import struct\n",
    "from absl import app, flags\n",
    "from ml_collections import config_flags\n",
    "from impls.agents import agents\n",
    "from impls.agents.crl import CRLAgent, get_config\n",
    "from config import SRC_ROOT_DIR\n",
    "from block_moving_env import *\n",
    "from main import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap environment\n",
    "NUM_ENVS = 1024\n",
    "MAX_REPLAY_SIZE = 10000\n",
    "BATCH_SIZE = 1024\n",
    "EPISODE_LENGTH = 100\n",
    "NUM_ACTIONS = 6\n",
    "GRID_SIZE = 10\n",
    "NUM_BOXES = 10\n",
    "SEED = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 19:48:05.565181: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3022] Can't reduce memory use below 8.57GiB (9204898148 bytes) by rematerialization; only reduced to 8.74GiB (9379840080 bytes), down from 8.74GiB (9379840080 bytes) originally\n"
     ]
    }
   ],
   "source": [
    "env = BoxPushingEnv(grid_size=GRID_SIZE, max_steps=EPISODE_LENGTH, number_of_boxes=NUM_BOXES)\n",
    "env = AutoResetWrapper(env)\n",
    "key = random.PRNGKey(SEED)\n",
    "env.step = jax.jit(jax.vmap(env.step))\n",
    "env.reset = jax.jit(jax.vmap(env.reset))\n",
    "jitted_flatten_batch = jax.jit(jax.vmap(flatten_batch, in_axes=(None, 0, 0)), static_argnums=(0,))\n",
    "\n",
    "# Replay buffer\n",
    "dummy_timestep = TimeStep(\n",
    "    key=key,\n",
    "    grid=jnp.zeros((GRID_SIZE, GRID_SIZE), dtype=jnp.int32),\n",
    "    agent_pos=jnp.zeros((2,), dtype=jnp.int32),\n",
    "    agent_has_box=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    steps=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    action=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    goal=jnp.zeros((GRID_SIZE, GRID_SIZE), dtype=jnp.int32),\n",
    "    reward=jnp.zeros((1,), dtype=jnp.int32),\n",
    "    done=jnp.zeros((1,), dtype=jnp.int32),\n",
    ")\n",
    "replay_buffer = jit_wrap(\n",
    "    TrajectoryUniformSamplingQueue(\n",
    "        max_replay_size=MAX_REPLAY_SIZE,\n",
    "        dummy_data_sample=dummy_timestep,\n",
    "        sample_batch_size=BATCH_SIZE,\n",
    "        num_envs=NUM_ENVS,\n",
    "        episode_length=EPISODE_LENGTH,\n",
    "    )\n",
    ")\n",
    "buffer_state = jax.jit(replay_buffer.init)(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent creation\n",
      "Agent created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Agent\n",
    "config = get_config()\n",
    "config['discrete'] = True\n",
    "agent_class = agents[config['agent_name']]\n",
    "example_batch = {\n",
    "    'observations':dummy_timestep.grid.reshape(1, -1),  # Add batch dimension \n",
    "    'actions': jnp.ones((1,), dtype=jnp.int32) * (NUM_ACTIONS-1), # TODO: make sure it should be the maximal value of action space  # Single action for batch size 1\n",
    "    'value_goals': dummy_timestep.grid.reshape(1, -1),\n",
    "    'actor_goals': dummy_timestep.grid.reshape(1, -1),\n",
    "}\n",
    "\n",
    "print(\"Testing agent creation\")\n",
    "agent = agent_class.create(\n",
    "    SEED,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'],\n",
    "    config,\n",
    "    example_batch['value_goals'],\n",
    ")\n",
    "print(\"Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_key = random.PRNGKey(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_step(carry, _):\n",
    "    buffer_state, agent, key = carry\n",
    "    key, batch_key, double_batch_key = jax.random.split(key, 3)\n",
    "    # Sample and process transitions\n",
    "    buffer_state, transitions = replay_buffer.sample(buffer_state)\n",
    "    batch_keys = jax.random.split(batch_key, transitions.grid.shape[0])\n",
    "    state, future_state, goal_index = jitted_flatten_batch(0.99, transitions, batch_keys)\n",
    "\n",
    "    state, actions, future_state, goal_index = apply_double_batch_trick(state, future_state, goal_index, double_batch_key)\n",
    "    # Create valid batch\n",
    "    valid_batch = {\n",
    "        'observations': state.grid.reshape(state.grid.shape[0], -1),\n",
    "        'actions': actions.squeeze(),\n",
    "        'value_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "        'actor_goals': future_state.grid.reshape(future_state.grid.shape[0], -1),\n",
    "    }\n",
    "\n",
    "    # Update agent\n",
    "    agent, update_info = agent.update(valid_batch)\n",
    "    return (buffer_state, agent, key), update_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def train_epoch(carry, _):\n",
    "    buffer_state, agent, key = carry\n",
    "    key, data_key, up_key = jax.random.split(key, 3)\n",
    "    _, _, timesteps = collect_data(agent, data_key, env, NUM_ENVS, EPISODE_LENGTH)\n",
    "    buffer_state = replay_buffer.insert(buffer_state, timesteps)\n",
    "    (buffer_state, agent, _), _ = jax.lax.scan(update_step, (buffer_state, agent, up_key), None, length=1000)\n",
    "    return (buffer_state, agent, key), None\n",
    "\n",
    "@jax.jit\n",
    "def train_n_epochs(buffer_state, agent, key):\n",
    "    (buffer_state, agent, key), _ = jax.lax.scan(\n",
    "        train_epoch,\n",
    "        (buffer_state, agent, key),\n",
    "        None,\n",
    "        length=10,\n",
    "    )\n",
    "    return buffer_state, agent, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "env = BoxPushingEnv(grid_size=GRID_SIZE, max_steps=EPISODE_LENGTH, number_of_boxes=NUM_BOXES)\n",
    "env = AutoResetWrapper(env)\n",
    "key = random.PRNGKey(SEED)\n",
    "# env.step = jax.jit(jax.vmap(env.step))\n",
    "# env.reset = jax.jit(jax.vmap(env.reset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 2, 2, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 2, 0, 3, 2],\n",
       "       [0, 0, 1, 0, 0, 2, 0, 0, 0, 2]], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 10, 10,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10, 10,  0, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10,  0,  3, 10],\n",
       "       [ 0,  0,  0,  0,  0, 10,  0,  0,  0, 10]], dtype=int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solved_state = env._env.create_solved_state(state)\n",
    "solved_state.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 2, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 2, 1, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 2, 2]], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_next, reward, done, info = env.step(solved_state, 2)\n",
    "state_next.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 True {'boxes_on_target': Array(10, dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._env._is_goal_reached(solved_state.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False | env._env._is_goal_reached(solved_state.grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 2, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 2, 1, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 2, 2]], dtype=int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_next.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridStatesEnum.project_to_no_target(state_next.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
